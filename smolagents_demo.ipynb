{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Hugging Face's Smolagents\n",
    "\n",
    "A stand-alone notebook, basicly a stripped-down copy of the article [Hugging Face's Smolagents: A Guide With Examples](https://app.datacamp.com/learn/tutorials/smolagents) in Datacamp. \n",
    "\n",
    "## What and why it is\n",
    "\n",
    "As described by Hugging Face’s [announcement blog](https://huggingface.co/blog/smolagents), **smolagents** is *“a very simple library that unlocks agentic capabilities for language models.”* \n",
    "\n",
    "At their heart, agents are powered by LLMs to dynamically solve a task by observing their environments, making plans, and executing those plans given their toolbox. Building these agents, while not impossible, requires you to write from scratch many components. These components ensure that the agents function properly without burning through your API credit and execution time. Agentic frameworks make this easier so you don’t have to reinvent the wheels.\n",
    "\n",
    "AI agent frameworks are often criticized with two points:\n",
    "\n",
    "- They build too many layers of abstraction, making them rigid and challenging to debug.\n",
    "- They focus on “workflows” rather than building agents that can dynamically collaborate on their own.\n",
    "\n",
    "On the other hand, smolagents has (we are told) qualities that make it very promising for these agentic applications:\n",
    "\n",
    "- The framework’s abstractions are kept at a minimum.\n",
    "- While most frameworks have the agents define their actions in JSON/text format, smolagents’ main approach is **Code Agents** in which actions are written as Python code snippets (this is different from agents that write code).\n",
    "- Being a Hugging Face framework, smolagents integrates well with the Hub and the Transformers library. You can use many models from the hub (some of them you can only use as a Pro user), and you can also work with proprietary models from OpenAI, Anthropic, etc.\n",
    "- You can easily utilize the already-provided tools, or define your custom tools with minimum effort, almost as simple as writing a Python function.\n",
    "\n",
    "## Building a Demo Project With Smolagents\n",
    "\n",
    "In this section, we will build a simple demo with smolagents. Our application will have an agent get the most upvoted paper on the Hugging Face [Daily Papers page](https://huggingface.co/papers). We build our custom tools for the agent and see it work in action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building custom tools\n",
    "\n",
    "While the framework provides built-in tools (e.g. DuckDuckGoSearchTool), building your custom tools is just as straightforward. We'll build four tools, each for a particular purpose:\n",
    "\n",
    "- Getting the title of the top daily paper.\n",
    "- Getting the ID of the paper using its title.\n",
    "- Downloading the paper from arXiv with the ID.\n",
    "- Reading the downloaded PDF file.\n",
    "\n",
    "It’s important to ensure agents clearly understand which tool to use and how to use it. To achieve this, be as explicit as possible when defining these tools:\n",
    "\n",
    "- Choose an informative name for the function.\n",
    "- The inputs and outputs of the function should have type hints.\n",
    "- A description of the tool's purpose must be included. This serves as a manual to the agent.\n",
    "\n",
    "#### Tool1: Get the title of the top daily paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from smolagents import tool \n",
    "# import packages that are used in our tools\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def get_hugging_face_top_daily_paper() -> str:\n",
    "    \"\"\"\n",
    "    This is a tool that returns the most upvoted paper on Hugging Face daily papers.\n",
    "    It returns the title of the paper\n",
    "    \"\"\"\n",
    "    try:\n",
    "      url = \"<https://huggingface.co/papers>\"\n",
    "      response = requests.get(url)\n",
    "      response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "      # Extract the title element from the JSON-like data in the \"data-props\" attribute\n",
    "      containers = soup.find_all('div', class_='SVELTE_HYDRATER contents')\n",
    "      top_paper = \"\"\n",
    "\n",
    "      for container in containers:\n",
    "          data_props = container.get('data-props', '')\n",
    "          if data_props:\n",
    "              try:\n",
    "                  # Parse the JSON-like string\n",
    "                  json_data = json.loads(data_props.replace('&quot;', '\"'))\n",
    "                  if 'dailyPapers' in json_data:\n",
    "                      top_paper = json_data['dailyPapers'][0]['title']\n",
    "              except json.JSONDecodeError:\n",
    "                  continue\n",
    "\n",
    "      return top_paper\n",
    "    except requests.exceptions.RequestException as e:\n",
    "      print(f\"Error occurred while fetching the HTML: {e}\")\n",
    "      return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool 2: Get the paper ID by its title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "@tool\n",
    "def get_paper_id_by_title(title: str) -> str:\n",
    "    \"\"\"\n",
    "    This is a tool that returns the arxiv paper id by its title.\n",
    "    It returns the title of the paper\n",
    "\n",
    "    Args:\n",
    "        title: The paper title for which to get the id.\n",
    "    \"\"\"\n",
    "    api = HfApi()\n",
    "    papers = api.list_papers(query=title)\n",
    "    if papers:\n",
    "        paper = next(iter(papers))\n",
    "        return paper.id\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool 3: Download the paper from arXiv with the ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "@tool\n",
    "def download_paper_by_id(paper_id: str) -> None:\n",
    "    \"\"\"\n",
    "    This tool gets the id of a paper and downloads it from arxiv. It saves the paper locally \n",
    "    in the current directory as \"paper.pdf\".\n",
    "\n",
    "    Args:\n",
    "        paper_id: The id of the paper to download.\n",
    "    \"\"\"\n",
    "    paper = next(arxiv.Client().results(arxiv.Search(id_list=[paper_id])))\n",
    "    paper.download_pdf(filename=\"paper.pdf\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool 4: Read a pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "@tool\n",
    "def read_pdf_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    This function reads the first three pages of a PDF file and returns its content as a string.\n",
    "    Args:\n",
    "        file_path: The path to the PDF file.\n",
    "        pages_to_read:\n",
    "    Returns:\n",
    "        A string containing the content of the PDF file.\n",
    "    \"\"\"\n",
    "    content = \"\"\n",
    "    reader = PdfReader('paper.pdf')\n",
    "    print(len(reader.pages))\n",
    "    pages = reader.pages[:3]\n",
    "    for page in pages:\n",
    "        content += page.extract_text()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sidebar (not in the original paper): Qwen models\n",
    "\n",
    "Qwen is  a series of large language models (LLMs) and large multimodal models (LMMs) that are designed to perform various tasks, including natural language understanding, mathematical problem-solving, and coding.\n",
    "\n",
    "Some of the key features and capabilities of Qwen include:\n",
    "\n",
    "- Strong performance: Qwen models have demonstrated competitive performance on various benchmarks, often outperforming similar-sized models.\n",
    "- Multimodal capabilities: Some Qwen models are multimodal, meaning they can process and understand both text and images.\n",
    "- Open source: Alibaba Cloud has made some of the Qwen models available open source, encouraging further research and development.\n",
    "\n",
    "Resources:\n",
    "- About Qwen: https://qwenlm.github.io/about/\n",
    "- GitHub: This is where you'll find the code, documentation, and updates for the Qwen models: https://github.com/QwenLM/Qwen\n",
    "- Hugging Face: You can explore the Qwen models, download them, and even try them out in your browser: https://huggingface.co/QwenLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "With our tools set up, we can now initialize and run our agent. We use the Qwen2.5-Coder-32B-Instruct model, which is free to use. The tools an agent needs can be passed while defining the agent. You can see the process of defining and running an agent requires minimum code.\n",
    "\n",
    "As the agent operates, it outputs its process step by step. This allows us to see how it defines its actions in code while utilizing the custom tools we’ve provided.\n",
    "\n",
    "Before running the agent, we must set the API key. We're using GitHub Secrets for storing the keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
    "\n",
    "model = HfApiModel(model_id=model_id, token=<YOUR-API>)\n",
    "agent = CodeAgent(tools=[get_hugging_face_top_daily_paper,\n",
    "                         get_paper_id_by_title,\n",
    "                         download_paper_by_id,\n",
    "                         read_pdf_file],\n",
    "                  model=model,\n",
    "                  add_base_tools=True)\n",
    "\n",
    "agent.run(\n",
    "    \"Summarize today's top paper on Hugging Face daily papers by reading it.\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
